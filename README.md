# Point-cloud-saliency-map-based-deep-neural-network-for-multiplex-immunophenotyping

Top: Representative mQIF of the tumor microenvironment of a breast cancer TMA core, stained for cell nuclei (DAPI, blue); CD8 (FITC, green); PDL-1 (Cy5, red); CD68 (TRITC, carmine); pan-cytokeratin (Cy7, cyan). Points (coordinate map) extracted using a commercial software package HALO where x and y-coordinates represents the physical cell location and z-coordinate represents the immunophenotype. Point cloud data used for the deep learning analysis in tiled-based processing. Bottom: The point cloud saliency map based deep learning strategy takes N points from the mQIF TMAs slides per tile. The data passes through feature extraction layers, a max pooling layer, classification layers and saliency maps construction. The feature extraction is comprised of five dense layers with 64, 64, 64, 128, and 1024 neurons, respectively, that share weights across each point. The max pooling layer applies a symmetric function reducing the features to 1024 Ã— 1 dimensions. The output of the max pooling layer is fed to two fully connected layers with 512 and 256 neurons, respectively, which is fed to a dropout layer and finally a softmax layer for classification. Saliency maps are then constructed to detect the key phenotypes of the DNN model by calculating gradients, which guide point-dropping in an iterative process as follows: compute the gradient, compute the spherical core, compute distance to the spherical core, construct the saliency score map, dropping points.

<img width="672" alt="image" src="https://github.com/user-attachments/assets/4a06a653-7895-4e25-a087-1ff15a9edb54" />
